{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model1 import bitext\n",
    "from model1 import Model1 as m1\n",
    "from model1 import*\n",
    "from collections import defaultdict\n",
    "from bleu import*\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### program has been submitted separately as a .py file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sample terminal input/output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.8 s, sys: 249 ms, total: 27 s\n",
      "Wall time: 27.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "IBM_model = None\n",
    "with open(\"hansards.36.ca.e.tok\", \"r\") as target:\n",
    "    with open(\"hansards.36.ca.f.tok\", \"r\") as source:\n",
    "        IBM_model = m1(source, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = IBM_model.train(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Best translation for the 50 French words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFFAIRES AFFAIRS\n",
      "AMENDEMENT AMENDMENT\n",
      "AUTOCHTONES ABORIGINAL\n",
      "CHAMBRE HOUSE\n",
      "CHEF LEADER\n",
      "COMITÉ COMMITTEE\n",
      "COMMERCE TRADE\n",
      "COMMUNES COMMONS\n",
      "DROITS RIGHTS\n",
      "DÉCLARATION STATEMENT\n",
      "DÉFENSE DEFENCE\n",
      "DÉVELOPPEMENT DEVELOPMENT\n",
      "ENFANTS CHILDREN\n",
      "FINANCES FINANCE\n",
      "FÉDÉRAL FEDERAL\n",
      "GENS PEOPLE\n",
      "GOUVERNEMENT GOVERNMENT\n",
      "GUERRE WAR\n",
      "HISTOIRE HISTORY\n",
      "INTERNATIONALE INTERNATIONAL\n",
      "JUGE JUSTICE\n",
      "MINISTÈRE DEPARTMENT\n",
      "MONDE WORLD\n",
      "NATIONALE NATIONAL\n",
      "PARLEMENT PARLIAMENT\n",
      "PAROLE SPEAK\n",
      "PARTIE PART\n",
      "PREMIER PRIME\n",
      "PREMIÈRE FIRST\n",
      "PROGRAMME PROGRAM\n",
      "PROJET BILL\n",
      "PROVINCE PROVINCE\n",
      "PRÉSIDENT SPEAKER\n",
      "QUÉBEC QUEBEC\n",
      "RAISON REASON\n",
      "RAPPORT REPORT\n",
      "RESPONSABILITÉ RESPONSIBILITY\n",
      "RÉGIME PLAN\n",
      "RÉGION REGION\n",
      "RÉPONSE ANSWER\n",
      "SECTEUR SECTOR\n",
      "SERVICES SERVICES\n",
      "SOCIÉTÉ SOCIETY\n",
      "SÉCURITÉ SECURITY\n",
      "SÉNAT SENATE\n",
      "SÉNATEUR SENATOR\n",
      "TRAVAIL WORK\n",
      "ÉGALEMENT ALSO\n",
      "ÉTATS-UNIS STATES\n",
      "ÉTUDE STUDY\n"
     ]
    }
   ],
   "source": [
    "fwords = []\n",
    "with open(\"fwords.txt\", \"r\") as fw:\n",
    "    for w in fw:\n",
    "        fwords.append(w.strip())\n",
    "translate(table, fwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approach/bugs/fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was initially having some problem with the data structure and my program took forever to compute. After having a discussion with you, I switched to using `deafultdicts` and only made entries for the sources/target words which are in the same bilingual parallel sentences. This greatly reduced the memory size and increased the speed of my program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = []\n",
    "hyps1 = []\n",
    "hyps2 = []\n",
    "with open(\"e.tox.tok\", \"r\") as ref:\n",
    "    for line in ref:\n",
    "        refs.append(line)\n",
    "with open(\"gtranslate.tok\", \"r\") as hyp:\n",
    "    for line in hyp:\n",
    "        hyps1.append(line)\n",
    "with open(\"systran.tok\", \"r\") as hyp:\n",
    "    for line in hyp:\n",
    "        hyps2.append(line)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtranslate score : 0.5719246937999647 systran score : 0.3922779324734805\n",
      "gtranslate score : 0.28568042338597716 systran score : 0.28956365673702783\n",
      "gtranslate score : 0.427639889086126 systran score : 0.4787898732732043\n",
      "gtranslate score : 0.4411629359322707 systran score : 0.3492382342001821\n",
      "gtranslate score : 0.2975990331686359 systran score : 0.25666772456849113\n",
      "gtranslate score : 0.9048374180359595 systran score : 0.8931539818068694\n",
      "gtranslate score : 0.2316809767568795 systran score : 0.4469948199291566\n",
      "gtranslate score : 0.40016016019225 systran score : 0.40652204338608683\n",
      "gtranslate score : 0.5842896293786666 systran score : 0.3815474751830903\n",
      "gtranslate score : 0.6999271023161167 systran score : 0.36939832906091624\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hyps)):\n",
    "    print(\"gtranslate score :\", BLEU(hyps1[i],refs[i]), \"systran score :\", BLEU(hyps2[i],refs[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discussion on BLEU score results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall I think gtranslate seems to be performing better than systran. The high score phrases were mostly noun to noun translations. But some sentences even though made sence and was conceptually correct surprisingly received a very low BLEU score. Like in this example where the reference was `MANY WILL LOSE THEIR RIGHT TO A PENSION IN THEIR OWN NAME BECAUSE OF THEIR HUSBAND 'S INCOME , WHILE MANY OTHERS WILL SEE THEIR PENSIONS REDUCED` and the sentence generated by gtranslate was `MANY WILL LOSE THEIR RIGHT TO A PENSION IN THEIR OWN NAME BECAUSE OF THEIR HUSBANDS ' INCOME WHILE OTHERS WILL REDUCE THE AMOUNT OF THEIR PENSION .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtranslate score : 0.5719246937999647 MANY WILL LOSE THEIR RIGHT TO A PENSION IN THEIR OWN NAME BECAUSE OF THEIR HUSBAND 'S INCOME , WHILE MANY OTHERS WILL SEE THEIR PENSIONS REDUCED .\n",
      " MANY WILL LOSE THEIR RIGHT TO A PENSION IN THEIR OWN NAME BECAUSE OF THEIR HUSBANDS ' INCOME WHILE OTHERS WILL REDUCE THE AMOUNT OF THEIR PENSION .\n",
      "\n",
      "gtranslate score : 0.28568042338597716 THE COMBINED PENSION WILL CREATE A PROBLEM FOR SENIOR WOMEN BECAUSE IT WILL ELIMINATE ALL THAT SOME OF THEM HAVE TO CALL THEIR OWN , TO BUY A GIFT FOR A GRANDCHILD PERHAPS , OR TO SPEND ON THEMSELVES .\n",
      " THE COMBINED PENSION WILL CREATE A PROBLEM FOR OLDER WOMEN BECAUSE IT ELIMINATES EVERYTHING THAT CAN CLAIM SOME OF THEM FOR THEIR PERSONAL PURCHASES OR , FOR EXAMPLE , TO BUY GIFTS FOR THEIR GRANDCHILDREN .\n",
      "\n",
      "gtranslate score : 0.427639889086126 HAS THE GOVERNMENT DONE ANY CALCULATIONS CONCERNING HOW THIS NEW MEASURE WILL AFFECT WOMEN ?\n",
      " THE GOVERNMENT HE CALCULATED THE IMPACT OF THE NEW BENEFIT WOMEN ?\n",
      "\n",
      "gtranslate score : 0.4411629359322707 IF SO , COULD THAT INFORMATION BE TABLED IN THE SENATE ?\n",
      " IF YES , THE INFORMATION COULD THEY BE TABLED IN THE SENATE ?\n",
      "\n",
      "gtranslate score : 0.2975990331686359 FOR EXAMPLE , COULD THE MINISTER REPORT AS TO HOW MANY WOMEN WILL NO LONGER BE ENTITLED TO A PENSION BECAUSE OF THE SENIORS BENEFIT , AND AS TO HOW MANY WOMEN WILL SEE REDUCED BENEFITS AND WHAT THE AVERAGE REDUCTIONS WILL BE ?\n",
      " FOR EXAMPLE , COULD THE MINISTER TELL US HOW MANY WOMEN WILL NOT BE ENTITLED TO A PENSION DUE TO THE PROVISION FOR SENIOR ( S ) , HOW MANY WOMEN WILL SEE THEIR BENEFITS REDUCED AND HOW THESE BENEFITS WILL BE REDUCED , ON AVERAGE ?\n",
      "\n",
      "gtranslate score : 0.9048374180359595 HON. B. ALASDAIR GRAHAM ( LEADER OF THE GOVERNMENT ) :\n",
      " B. ALASDAIR GRAHAM ( LEADER OF THE GOVERNMENT ) :\n",
      "\n",
      "gtranslate score : 0.2316809767568795 HONOURABLE SENATORS , IT IS QUITE CLEAR THAT THE AGEING OF OUR POPULATION IS RESULTING IN MAJOR COST INCREASES .\n",
      " HONOURABLE SENATORS , IT IS CLEAR THAT OUR AGING POPULATION LEADS TO INCREASED COSTS FOR THE GOVERNMENT .\n",
      "\n",
      "gtranslate score : 0.40016016019225 SOME COUPLES RECEIVE HIGHER BENEFITS THAN OTHERS EVEN THOUGH THEIR OVERALL INCOME IS THE SAME .\n",
      " SOME COUPLES RECEIVE HIGHER THAN OTHERS EVEN IF THEIR TOTAL INCOME IS THE SAME BENEFITS .\n",
      "\n",
      "gtranslate score : 0.5842896293786666 THE SYSTEM IS VERY COMPLEX AND IT IS CERTAINLY A BURDEN ON SENIORS .\n",
      " THE SYSTEM IS VERY COMPLEX AND IT IS A BURDEN FOR THE ELDERLY .\n",
      "\n",
      "gtranslate score : 0.6999271023161167 THE GOVERNMENT IS TRYING TO PRESERVE AND STRENGTHEN THE SYSTEM .\n",
      " THE GOVERNMENT IS TRYING TO PROTECT AND STRENGTHEN THE SYSTEM .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hyps)):\n",
    "    print(\"gtranslate score :\", BLEU(hyps1[i],refs[i]), refs[i], hyps1[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Approach/bugs/fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I pretty much followed the equations given on the paper. I had a list of initialized which could hold all the modified precisions. My function then loops over different ngrams and computes the sum. I ran into two bugs which I was able to fix with some debugging. I was initially getting zero BLEU scores for all the translations. I then printed my counters to see if the ngram counts are being changed. The counts weren't changing because, I was calling `list()` on the input sentence which passed characters to the ngram function instead of words. I then fixed it by using the `split()` method. Another bug I had was, I was getting negative scores for some reason and I then instantly noticed that I was directly multiplying the penalty with sum instead of multiplying with the exponential. After I fixed it, BLEU scores seemed reasonable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
