## Experiment1

Overall, there is a good improvement in the confusion matrix. Adding a hidden layer definitely decreased the number of times a number is being confused with a different number.

#### n = 10

![alt text](E1N10.png)

Confusion matrix
```python
[[9.500e+02 0.000e+00 1.000e+00 2.000e+00 7.000e+00 1.000e+00 7.000e+00
  2.000e+00 6.000e+00 4.000e+00]
 [0.000e+00 1.113e+03 5.000e+00 4.000e+00 0.000e+00 1.000e+00 3.000e+00
  1.000e+00 7.000e+00 1.000e+00]
 [1.500e+01 5.000e+00 8.700e+02 5.900e+01 9.000e+00 2.000e+00 1.500e+01
  9.000e+00 3.900e+01 9.000e+00]
 [5.000e+00 0.000e+00 2.200e+01 9.210e+02 5.000e+00 2.100e+01 3.000e+00
  1.600e+01 1.400e+01 3.000e+00]
 [2.000e+00 2.000e+00 6.000e+00 1.000e+00 8.910e+02 2.000e+00 5.000e+00
  2.000e+00 1.000e+00 7.000e+01]
 [1.400e+01 2.000e+00 3.000e+00 5.500e+01 2.700e+01 7.370e+02 1.300e+01
  7.000e+00 2.000e+01 1.400e+01]
 [1.900e+01 3.000e+00 4.000e+00 0.000e+00 2.700e+01 2.900e+01 8.500e+02
  0.000e+00 1.900e+01 7.000e+00]
 [4.000e+00 8.000e+00 2.100e+01 9.000e+00 7.000e+00 3.000e+00 1.000e+00
  9.180e+02 5.000e+00 5.200e+01]
 [1.300e+01 6.000e+00 3.000e+00 4.300e+01 2.300e+01 2.000e+01 4.000e+00
  1.400e+01 8.230e+02 2.500e+01]
 [8.000e+00 4.000e+00 0.000e+00 2.100e+01 3.200e+01 5.000e+00 0.000e+00
  2.100e+01 2.000e+00 9.160e+02]]
```

#### n = 20

![alt text](E1N20.png)

Confusion matrix

```python
[[9.540e+02 0.000e+00 0.000e+00 0.000e+00 1.000e+00 3.000e+00 1.400e+01
  2.000e+00 5.000e+00 1.000e+00]
 [0.000e+00 1.116e+03 4.000e+00 2.000e+00 0.000e+00 1.000e+00 3.000e+00
  1.000e+00 7.000e+00 1.000e+00]
 [4.000e+00 2.000e+00 9.400e+02 1.100e+01 7.000e+00 1.000e+00 1.800e+01
  7.000e+00 3.400e+01 8.000e+00]
 [2.000e+00 0.000e+00 1.400e+01 9.490e+02 0.000e+00 1.200e+01 6.000e+00
  9.000e+00 1.300e+01 5.000e+00]
 [1.000e+00 1.000e+00 3.000e+00 1.000e+00 9.170e+02 0.000e+00 1.300e+01
  0.000e+00 4.000e+00 4.200e+01]
 [4.000e+00 2.000e+00 3.000e+00 3.800e+01 4.000e+00 7.770e+02 1.900e+01
  4.000e+00 2.800e+01 1.300e+01]
 [1.200e+01 3.000e+00 1.000e+00 1.000e+00 8.000e+00 9.000e+00 9.110e+02
  0.000e+00 1.200e+01 1.000e+00]
 [2.000e+00 4.000e+00 2.400e+01 9.000e+00 1.200e+01 1.000e+00 0.000e+00
  9.290e+02 1.100e+01 3.600e+01]
 [8.000e+00 1.000e+00 3.000e+00 2.000e+01 8.000e+00 7.000e+00 1.300e+01
  4.000e+00 9.020e+02 8.000e+00]
 [4.000e+00 6.000e+00 2.000e+00 2.300e+01 1.200e+01 1.000e+00 3.000e+00
  1.100e+01 1.300e+01 9.340e+02]]
```

#### n = 100
![alt text](E1N100.png)

```python
[[9.720e+02 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 2.000e+00
  1.000e+00 3.000e+00 0.000e+00]
 [0.000e+00 1.119e+03 4.000e+00 3.000e+00 0.000e+00 1.000e+00 2.000e+00
  1.000e+00 5.000e+00 0.000e+00]
 [4.000e+00 3.000e+00 1.000e+03 6.000e+00 4.000e+00 0.000e+00 2.000e+00
  5.000e+00 7.000e+00 1.000e+00]
 [0.000e+00 1.000e+00 3.000e+00 9.880e+02 1.000e+00 3.000e+00 0.000e+00
  5.000e+00 6.000e+00 3.000e+00]
 [2.000e+00 0.000e+00 2.000e+00 0.000e+00 9.470e+02 0.000e+00 4.000e+00
  0.000e+00 2.000e+00 2.500e+01]
 [3.000e+00 0.000e+00 1.000e+00 1.400e+01 1.000e+00 8.450e+02 1.000e+01
  3.000e+00 8.000e+00 7.000e+00]
 [6.000e+00 3.000e+00 3.000e+00 1.000e+00 1.000e+00 6.000e+00 9.300e+02
  0.000e+00 7.000e+00 1.000e+00]
 [1.000e+00 2.000e+00 6.000e+00 6.000e+00 5.000e+00 0.000e+00 0.000e+00
  9.960e+02 2.000e+00 1.000e+01]
 [3.000e+00 2.000e+00 2.000e+00 4.000e+00 4.000e+00 3.000e+00 4.000e+00
  4.000e+00 9.450e+02 3.000e+00]
 [3.000e+00 4.000e+00 1.000e+00 5.000e+00 1.000e+01 2.000e+00 0.000e+00
  5.000e+00 1.000e+00 9.780e+02]]
```



###### Q: How does the number of hidden units affect the final accuracy on the test data?
 Accuracy is getting better as the number of hidden units are being increased

###### Q: How does it affect the number of epochs needed for training to converge?
The more number of hidden units the less number of epochs it took to converge.

###### Q: Is there evidence that any of your networks has overfit to the training data? If so, what is that evidence?
I didn't notice any kind of overfitting since all the plots seems to converge at some point.

###### Q: How do your results compare to the results obtained by your perceptron in HW1?
The accuracy on the test data has significantly improved compared to the first homework.

##### Experiment2

###### with m = 0
![alt text](E2M0.png)

```python
[[9.710e+02 1.000e+00 1.000e+00 1.000e+00 0.000e+00 2.000e+00 2.000e+00
  1.000e+00 1.000e+00 0.000e+00]
 [0.000e+00 1.123e+03 1.000e+00 4.000e+00 0.000e+00 1.000e+00 2.000e+00
  1.000e+00 3.000e+00 0.000e+00]
 [3.000e+00 3.000e+00 1.005e+03 5.000e+00 2.000e+00 0.000e+00 3.000e+00
  6.000e+00 5.000e+00 0.000e+00]
 [1.000e+00 0.000e+00 2.000e+00 9.950e+02 0.000e+00 5.000e+00 0.000e+00
  3.000e+00 2.000e+00 2.000e+00]
 [1.000e+00 1.000e+00 1.000e+00 1.000e+00 9.620e+02 0.000e+00 4.000e+00
  0.000e+00 0.000e+00 1.200e+01]
 [4.000e+00 0.000e+00 0.000e+00 1.000e+01 1.000e+00 8.600e+02 7.000e+00
  4.000e+00 2.000e+00 4.000e+00]
 [7.000e+00 3.000e+00 0.000e+00 1.000e+00 0.000e+00 6.000e+00 9.340e+02
  0.000e+00 7.000e+00 0.000e+00]
 [1.000e+00 3.000e+00 1.000e+01 2.000e+00 2.000e+00 1.000e+00 1.000e+00
  9.950e+02 3.000e+00 1.000e+01]
 [4.000e+00 2.000e+00 3.000e+00 3.000e+00 3.000e+00 4.000e+00 2.000e+00
  3.000e+00 9.480e+02 2.000e+00]
 [3.000e+00 3.000e+00 0.000e+00 6.000e+00 8.000e+00 1.000e+00 0.000e+00
  5.000e+00 5.000e+00 9.780e+02]]
```

###### with m = 0.5
![alt text](E2M05.png)

```python
[[9.680e+02 1.000e+00 1.000e+00 1.000e+00 0.000e+00 1.000e+00 5.000e+00
  1.000e+00 1.000e+00 1.000e+00]
 [0.000e+00 1.125e+03 2.000e+00 2.000e+00 0.000e+00 2.000e+00 1.000e+00
  1.000e+00 2.000e+00 0.000e+00]
 [4.000e+00 1.000e+00 9.990e+02 7.000e+00 2.000e+00 0.000e+00 5.000e+00
  8.000e+00 5.000e+00 1.000e+00]
 [1.000e+00 0.000e+00 3.000e+00 9.910e+02 1.000e+00 3.000e+00 0.000e+00
  4.000e+00 3.000e+00 4.000e+00]
 [1.000e+00 1.000e+00 1.000e+00 1.000e+00 9.440e+02 0.000e+00 6.000e+00
  1.000e+00 2.000e+00 2.500e+01]
 [5.000e+00 0.000e+00 0.000e+00 6.000e+00 0.000e+00 8.600e+02 8.000e+00
  1.000e+00 6.000e+00 6.000e+00]
 [3.000e+00 3.000e+00 1.000e+00 1.000e+00 0.000e+00 4.000e+00 9.410e+02
  0.000e+00 5.000e+00 0.000e+00]
 [0.000e+00 5.000e+00 1.000e+01 4.000e+00 1.000e+00 0.000e+00 0.000e+00
  9.920e+02 3.000e+00 1.300e+01]
 [4.000e+00 2.000e+00 5.000e+00 2.000e+00 3.000e+00 2.000e+00 1.000e+00
  4.000e+00 9.470e+02 4.000e+00]
 [2.000e+00 5.000e+00 0.000e+00 5.000e+00 8.000e+00 0.000e+00 1.000e+00
  3.000e+00 3.000e+00 9.820e+02]]
```
###### with m = 0.9
#### n = 100
I'm including this graph again since it was mentioned to do so in the assignment.
![alt text](E1N100.png)

```python
[[9.720e+02 1.000e+00 0.000e+00 1.000e+00 0.000e+00 0.000e+00 2.000e+00
  1.000e+00 3.000e+00 0.000e+00]
 [0.000e+00 1.119e+03 4.000e+00 3.000e+00 0.000e+00 1.000e+00 2.000e+00
  1.000e+00 5.000e+00 0.000e+00]
 [4.000e+00 3.000e+00 1.000e+03 6.000e+00 4.000e+00 0.000e+00 2.000e+00
  5.000e+00 7.000e+00 1.000e+00]
 [0.000e+00 1.000e+00 3.000e+00 9.880e+02 1.000e+00 3.000e+00 0.000e+00
  5.000e+00 6.000e+00 3.000e+00]
 [2.000e+00 0.000e+00 2.000e+00 0.000e+00 9.470e+02 0.000e+00 4.000e+00
  0.000e+00 2.000e+00 2.500e+01]
 [3.000e+00 0.000e+00 1.000e+00 1.400e+01 1.000e+00 8.450e+02 1.000e+01
  3.000e+00 8.000e+00 7.000e+00]
 [6.000e+00 3.000e+00 3.000e+00 1.000e+00 1.000e+00 6.000e+00 9.300e+02
  0.000e+00 7.000e+00 1.000e+00]
 [1.000e+00 2.000e+00 6.000e+00 6.000e+00 5.000e+00 0.000e+00 0.000e+00
  9.960e+02 2.000e+00 1.000e+01]
 [3.000e+00 2.000e+00 2.000e+00 4.000e+00 4.000e+00 3.000e+00 4.000e+00
  4.000e+00 9.450e+02 3.000e+00]
 [3.000e+00 4.000e+00 1.000e+00 5.000e+00 1.000e+01 2.000e+00 0.000e+00
  5.000e+00 1.000e+00 9.780e+02]]
```
###### with m = 1
I couldn't run the experiment with a momentum of 1. I got an overflow error

###### Q: How does the momentum value affect the final accuracy on the test data?
Having a lower momentum tends to increase the accuracy on the test data

###### Q: How does it affect the number of epochs needed for training to converge?
I didn't notice much difference in the number of epochs needed to train in order to converge between 0 and 0.5

###### Q: Again, is there evidence that any of your networks has overfit to the training data?  If so, what is that evidence?
No, the test plot seems to be not diverging from the training plot. So there seems to be no overfitting

##### Experiment3

![alt text](E3D1.png)

```python
[[9.640e+02 0.000e+00 1.000e+00 2.000e+00 0.000e+00 8.000e+00 1.000e+00
  3.000e+00 0.000e+00 1.000e+00]
 [0.000e+00 1.118e+03 6.000e+00 1.000e+00 0.000e+00 1.000e+00 3.000e+00
  1.000e+00 5.000e+00 0.000e+00]
 [2.100e+01 2.000e+00 9.650e+02 6.000e+00 8.000e+00 3.000e+00 6.000e+00
  1.100e+01 9.000e+00 1.000e+00]
 [6.000e+00 0.000e+00 1.000e+01 9.250e+02 5.000e+00 3.800e+01 0.000e+00
  9.000e+00 1.400e+01 3.000e+00]
 [1.000e+00 1.000e+00 3.000e+00 0.000e+00 9.560e+02 0.000e+00 5.000e+00
  2.000e+00 2.000e+00 1.200e+01]
 [1.000e+01 0.000e+00 2.000e+00 1.000e+01 5.000e+00 8.530e+02 7.000e+00
  2.000e+00 0.000e+00 3.000e+00]
 [1.600e+01 4.000e+00 1.000e+00 1.000e+00 2.500e+01 1.500e+01 8.910e+02
  1.000e+00 4.000e+00 0.000e+00]
 [2.000e+00 1.100e+01 1.200e+01 3.000e+00 5.000e+00 1.000e+00 0.000e+00
  9.800e+02 2.000e+00 1.200e+01]
 [1.700e+01 2.000e+00 5.000e+00 7.000e+00 1.200e+01 1.700e+01 4.000e+00
  5.000e+00 8.990e+02 6.000e+00]
 [1.100e+01 8.000e+00 0.000e+00 4.000e+00 3.000e+01 1.000e+01 0.000e+00
  1.300e+01 8.000e+00 9.250e+02]]
```

![alt text](E3D2.png)

```python
[[9.570e+02 0.000e+00 2.000e+00 1.000e+00 4.000e+00 2.000e+00 9.000e+00
  2.000e+00 3.000e+00 0.000e+00]
 [0.000e+00 1.113e+03 5.000e+00 3.000e+00 1.000e+00 2.000e+00 3.000e+00
  1.000e+00 7.000e+00 0.000e+00]
 [5.000e+00 3.000e+00 9.980e+02 4.000e+00 4.000e+00 1.000e+00 1.000e+00
  9.000e+00 7.000e+00 0.000e+00]
 [2.000e+00 0.000e+00 1.500e+01 9.400e+02 1.000e+00 2.500e+01 1.000e+00
  1.300e+01 1.300e+01 0.000e+00]
 [1.000e+00 1.000e+00 5.000e+00 0.000e+00 9.490e+02 0.000e+00 9.000e+00
  2.000e+00 6.000e+00 9.000e+00]
 [6.000e+00 1.000e+00 6.000e+00 6.000e+00 1.000e+00 8.500e+02 6.000e+00
  2.000e+00 1.000e+01 4.000e+00]
 [9.000e+00 3.000e+00 1.000e+01 0.000e+00 7.000e+00 8.000e+00 9.150e+02
  0.000e+00 6.000e+00 0.000e+00]
 [3.000e+00 1.100e+01 1.700e+01 5.000e+00 3.000e+00 1.000e+00 0.000e+00
  9.690e+02 3.000e+00 1.600e+01]
 [4.000e+00 3.000e+00 1.200e+01 1.400e+01 9.000e+00 7.000e+00 4.000e+00
  5.000e+00 9.150e+02 1.000e+00]
 [7.000e+00 6.000e+00 1.000e+00 1.200e+01 5.100e+01 7.000e+00 1.000e+00
  1.300e+01 1.000e+01 9.010e+02]]
```

###### Q: How does the size of the training data affect the final accuracy on the test data?
Accuracy tends to get better with more training data

###### Q: How does it affect the number of epochs needed for training to converge?
Having more data took less number of epochs to converge

###### Q: Again, is there evidence that any of your networks has overfit to the training data?  If so, what is that evidence?
No, the testing plot seems to converge the training plot. So there seems to be no overfitting.
