{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this homework we will use GaussianNaïve Bayes and Logistic Regression to classify the Spambasedatafrom the UCI ML repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Creating training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_data = pd.read_csv(\"spambase.data\")\n",
    "X = spam_data.iloc[:,:-1]\n",
    "y = spam_data.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam prior for training: 0.3917391304347826\n",
      "Not Spam prior for training: 0.6082608695652174\n"
     ]
    }
   ],
   "source": [
    "S_prior = len([y for y in y_train if y == 1])/len(y_train)\n",
    "NS_prior = len([y for y in y_train if y == 0])/len(y_train)\n",
    "print(f\"Spam prior for training: {S_prior}\")\n",
    "print(f\"Not Spam prior for training: {NS_prior}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_mean(data):\n",
    "    return float(sum(data) / len(data))\n",
    "\n",
    "def stddev(data):\n",
    "    mu = cal_mean(data)\n",
    "    nume = cal_mean([(x - mu) ** 2 for x in data])\n",
    "    return np.sqrt(nume) if np.sqrt(nume) > 0 else 0.0001\n",
    "\n",
    "    \n",
    "mean_std_spam = []\n",
    "mean_std_notspam = []\n",
    "for i in range(57):\n",
    "    feature = np.asarray(X_train.iloc[:,i])\n",
    "    spam_list = []\n",
    "    notspam_list = []\n",
    "    for i,v in enumerate(y_train):\n",
    "        if v == 1:\n",
    "            spam_list.append(feature[i])\n",
    "        else:\n",
    "            notspam_list.append(feature[i])\n",
    "    mean_std_spam.append((cal_mean(spam_list),stddev(spam_list)))\n",
    "    mean_std_notspam.append((cal_mean(notspam_list),stddev(notspam_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_pdf(x,mu,sigma):\n",
    "    return np.exp(-(x-mu)**2/(2*(sigma **2)))\n",
    "\n",
    "predicted = np.zeros(len(y_test))\n",
    "test_examples = np.asarray(X_test)\n",
    "for i,ex in enumerate(test_examples):\n",
    "    P_Spam = 0\n",
    "    P_NOTSpam = 0\n",
    "    \n",
    "    for j,feature in enumerate(ex):\n",
    "        N_S = -999999\n",
    "        N_NS = -999999\n",
    "        mean_S,std_S = mean_std_spam[j]\n",
    "        mean_NS,std_NS = mean_std_notspam[j]\n",
    "        \n",
    "        pdf_S = cal_pdf(feature,mean_S,std_S)\n",
    "        if pdf_S != 0:\n",
    "            N_S = np.log(pdf_S/(np.sqrt(2*np.pi)*std_S))\n",
    "            \n",
    "        pdf_NS = cal_pdf(feature,mean_NS,std_NS)\n",
    "        if pdf_NS != 0:\n",
    "            N_NS = np.log(pdf_NS/(np.sqrt(2*np.pi)*std_NS)) \n",
    "            \n",
    "        P_Spam += N_S\n",
    "        P_NOTSpam += N_NS\n",
    "        \n",
    "    P_Spam += np.log(S_prior)\n",
    "    P_NOTSpam += np.log(NS_prior)\n",
    "    if P_Spam > P_NOTSpam:\n",
    "        predicted[i] = 1\n",
    "    else:\n",
    "        predicted[i] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8147826086956522\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test,predicted)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.72      0.82      1389\n",
      "          1       0.69      0.96      0.80       911\n",
      "\n",
      "avg / total       0.86      0.81      0.82      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[998 391]\n",
      " [ 35 876]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got an accuracy of `81%` which I think is pretty low. But the model seems to have a very high recall, but again very low precision. \n",
    "\n",
    "With `Naïve Bayes` I got a lower accuracy compared to the one I got with `SVM` on Homework 3. By just looking at the overall accuracy it seems like the attributes are indeed dependent at some level. `Naïve Bayes` seems to have a pretty good recall score(higher than `SVM`) for `spam` class which seems to be good attribute for a model dealing with email spam classification, meaning it was able to predict all most all of the correct spam emails. But on the downside it does have a lower precision score which seems to be a concern because it seems to be classifying non-spam emails as spam. This attribute can be big no if someone wants to use this as a model for classifying spams emails, becuase they would be loosing important emails which are mistakenly classified as spam.\n",
    "\n",
    "The reason why it has a very high recall and low precision for `spam class` might be because, it is computing the independent probablities of features given a spam email. But doing this comes with a cost. Since the `Naïve Bayes` model assumes that all the features are independent, it is agnostic to feature dependency. So becuase of this it might miss out on feature dependencies where even though some emails have spam features, they might actually not be spam features becuase there was some other feature which was negating it. Due to this Naïve Bayes model classifies some non-spam emails as spam just because it saw some spam feautures in the text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) Describe what library you used and what parameter values you used in running logistic regression.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used sklearn library for my logistic regression. I used `multinomial logistic regression` as my classification model. I used `lbfgs` as my solver parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) Give the accuracy, precision, and recall of your learned model on the test set, as well as a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9173913043478261\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test,clf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.94      0.93      1389\n",
      "          1       0.91      0.88      0.89       911\n",
      "\n",
      "avg / total       0.92      0.92      0.92      2300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[998 391]\n",
      " [ 35 876]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) Write a few sentences comparing the results of logistic regression to those you obtained from Naïve Bayes and from your SVMfrom Homework 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Logistic regression` seems to have a good balance between precision and recall scores for `not spam` class with an overall accuracy of `92%`. I think `Logistic regression` model seems to have ideal scores to be spam classifer than `Naïve Bayes`.  I say this because, for email classifer we don't mind a few spam email in our regular email and we do mind if some of our important email ends up in the spam folder. So here we are looking for a model which has high recall, meaning we want to reduce the number of good emails being wrongly classified as spam and we want a model to have high precision, meaning we want to also reduce spam emails being sent to our inbox. `SVM` from homework 3 seems to perform slightly better than `Logistic regression` in terms of overall accuracy. They both have same recall, but `SVM` seems to have a slightly higher precision for `spam` class. `Logistic regression` seems to perform better than `Naïve Bayes` in terms of overall accuracy and precision for `spam` class. But `Naïve Bayes` model seems to have a higher recall compared to all the models for `spam` class. But `Logistic regression` out performs `Naïve Bayes` in `not spam` class with a very higher precision and recall values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
